{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DZ_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sILpntiDJGT"
      },
      "source": [
        "Домашнее задание\n",
        "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
        "2. при обучении моделей обязательно использовать кроссвалидацию\n",
        "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
        "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
        "5. (опциональный вопрос) какой график (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого, например, 1 к 1000).\n",
        "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
        "\n",
        "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно).\n",
        "Допустим, у нас две модели:\n",
        "\n",
        "первая помечает 100 объектов как класс 1, но TP = 90\n",
        "вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
        "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?\n",
        "\n",
        "Ссылки\n",
        "https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/\n",
        "https://en.wikipedia.org/wiki/Receiver_operating_characteristic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMyGQ5OYDNc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "8347c4bd-e7ef-4976-b5ef-6404f4f8fbfb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
        "\n",
        "# df = pd.read_csv('train_case2.csv', ';')\n",
        "df = pd.read_csv('/content/sample_data/train_case2.csv', ';')\n",
        "df.head(3)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>ap_hi</th>\n",
              "      <th>ap_lo</th>\n",
              "      <th>cholesterol</th>\n",
              "      <th>gluc</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alco</th>\n",
              "      <th>active</th>\n",
              "      <th>cardio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18393</td>\n",
              "      <td>2</td>\n",
              "      <td>168</td>\n",
              "      <td>62.0</td>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20228</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>85.0</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18857</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>64.0</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    age  gender  height  weight  ...  gluc  smoke  alco  active  cardio\n",
              "0   0  18393       2     168    62.0  ...     1      0     0       1       0\n",
              "1   1  20228       1     156    85.0  ...     1      0     0       1       1\n",
              "2   2  18857       1     165    64.0  ...     1      0     0       0       1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5YHJXMLE94H"
      },
      "source": [
        "#разделим данные на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
        "                                                    df['cardio'], random_state=0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbWzMwHDGGAi"
      },
      "source": [
        "К полям:\n",
        "- gender, cholesterol применим OHE-кодирование\n",
        "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
        "- gluc, smoke, alco, active - оставим пока как есть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BKF_vvUFFbU"
      },
      "source": [
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]\n",
        "    \n",
        "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.columns = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.get_dummies(X, prefix=self.key)\n",
        "        test_columns = [col for col in X.columns]\n",
        "        for col_ in test_columns:\n",
        "            if col_ not in self.columns:\n",
        "                X[col_] = 0\n",
        "        return X[self.columns]\n",
        "\n",
        "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "cat_cols = ['gender', 'cholesterol']\n",
        "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
        "\n",
        "continuos_transformers = []\n",
        "cat_transformers = []\n",
        "base_transformers = []\n",
        "\n",
        "for cont_col in continuos_cols:\n",
        "    transfomer =  Pipeline([\n",
        "                ('selector', NumberSelector(key=cont_col)),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "    continuos_transformers.append((cont_col, transfomer))\n",
        "    \n",
        "for cat_col in cat_cols:\n",
        "    cat_transformer = Pipeline([\n",
        "                ('selector', ColumnSelector(key=cat_col)),\n",
        "                ('ohe', OHEEncoder(key=cat_col))\n",
        "            ])\n",
        "    cat_transformers.append((cat_col, cat_transformer))\n",
        "    \n",
        "for base_col in base_cols:\n",
        "    base_transformer = Pipeline([\n",
        "                ('selector', NumberSelector(key=base_col))\n",
        "            ])\n",
        "    base_transformers.append((base_col, base_transformer))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djX3pFtnFO3a"
      },
      "source": [
        "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
        "\n",
        "# feature_processing = Pipeline([('feats', feats)])\n",
        "# feature_processing.fit_transform(X_train)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-XNX61vHvSc"
      },
      "source": [
        "Добавим классификатор и запустим кросс-валидацию для моделей логистической LogisticRegression, RandomForest и XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CH-2-srIY0F"
      },
      "source": [
        "Обернем кроссвалидацию в функцию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GEbW4eBIcRE"
      },
      "source": [
        "def my_cv(model, X_train, y_train):\n",
        "    #запустим кросс-валидацию\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "    cv_score = np.mean(cv_scores)\n",
        "    cv_score_std = np.std(cv_scores)\n",
        "    print('CV score is {}+-{}'.format(cv_score, cv_score_std))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6iDuh7HoU-",
        "outputId": "287fa4c7-f4c2-439c-8613-4c71fc7998f1"
      },
      "source": [
        "LR_cls = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', LogisticRegression(random_state = 42)),\n",
        "])\n",
        "my_cv(LR_cls, X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.7867401104915408+-0.00852135511666111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tjYNWM_J0jP",
        "outputId": "38c3274e-ecf2-467c-e6f2-d269184661d0"
      },
      "source": [
        "RF_cls = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', RandomForestClassifier(random_state=42,\n",
        "                                         max_depth=10)),\n",
        "])\n",
        "my_cv(RF_cls, X_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.8012814315210153+-0.006725085121681367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRDVJSG9J0xR",
        "outputId": "55e26fe5-0577-49a1-f30b-154fd5a00122"
      },
      "source": [
        "XGB_cls = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', XGBClassifier(random_state = 42,\n",
        "                                 eta=0.3,\n",
        "                                 max_depth=4)),\n",
        "])\n",
        "my_cv(XGB_cls, X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.8030305340079853+-0.007090010275957017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOC5MHFFQNtZ"
      },
      "source": [
        "# оформим в функцию расчет метрик\n",
        "def metrics(y_test, preds):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "    print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                            fscore[ix],\n",
        "                                                                            precision[ix],\n",
        "                                                                            recall[ix]))\n",
        "    return precision, recall, thresholds, ix, fscore"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz70QTNFT2EP",
        "outputId": "3801b8be-2948-4350-dfb0-704881be633e"
      },
      "source": [
        "LR_cls.fit(X_train, y_train)\n",
        "RF_cls.fit(X_train, y_train)\n",
        "XGB_cls.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('features',\n",
              "                 FeatureUnion(n_jobs=None,\n",
              "                              transformer_list=[('age',\n",
              "                                                 Pipeline(memory=None,\n",
              "                                                          steps=[('selector',\n",
              "                                                                  NumberSelector(key='age')),\n",
              "                                                                 ('standard',\n",
              "                                                                  StandardScaler(copy=True,\n",
              "                                                                                 with_mean=True,\n",
              "                                                                                 with_std=True))],\n",
              "                                                          verbose=False)),\n",
              "                                                ('height',\n",
              "                                                 Pipeline(memory=None,\n",
              "                                                          steps=[('selector',\n",
              "                                                                  NumberSelector(key='height')),\n",
              "                                                                 ('standard',\n",
              "                                                                  StandardScaler(c...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, eta=0.3, gamma=0,\n",
              "                               learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=None,\n",
              "                               objective='binary:logistic', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfVDMf-jUZaK"
      },
      "source": [
        "y_score_LR = LR_cls.predict_proba(X_test)[:, 1]\n",
        "y_score_RF = RF_cls.predict_proba(X_test)[:, 1]\n",
        "y_score_XGB = XGB_cls.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap1IXAZkVv9F",
        "outputId": "432230d3-0db3-49ee-cdbc-6b2770c81313"
      },
      "source": [
        "precision_LR, recall_LR, thresholds_LR, ix_LR, fscore_LR = metrics(y_test, y_score_LR)\n",
        "precision_RF, recall_RF, thresholds_RF, ix_RF, fscore_RF = metrics(y_test, y_score_RF)\n",
        "precision_XGB, recall_XGB, thresholds_XGB, ix_XGB, fscore_XGB = metrics(y_test, y_score_XGB)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold=0.386937, F-Score=0.730, Precision=0.647, Recall=0.838\n",
            "Best Threshold=0.400248, F-Score=0.740, Precision=0.697, Recall=0.790\n",
            "Best Threshold=0.371986, F-Score=0.740, Precision=0.682, Recall=0.809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316p1-6xXgV4",
        "outputId": "c89f1c3c-b3f6-446a-ae66-870c119ab880"
      },
      "source": [
        "roc_auc_score_LR = roc_auc_score(y_test, y_score_LR)\n",
        "roc_auc_score_LR"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7840347790421852"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDP8T3fMXmbo",
        "outputId": "5f8d581a-4681-4a09-c2b6-76b42d1197b0"
      },
      "source": [
        "roc_auc_score_RF = roc_auc_score(y_test, y_score_RF)\n",
        "roc_auc_score_RF"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8015363399584103"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9f_x--4XmPJ",
        "outputId": "cec07c0a-bd71-4ca1-c92d-5ee26b493019"
      },
      "source": [
        "roc_auc_score_XGB = roc_auc_score(y_test, y_score_XGB)\n",
        "roc_auc_score_XGB"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.803003366092981"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "vpNyoF9gX007",
        "outputId": "94103f2d-9196-4c15-be1a-d74a39276a9c"
      },
      "source": [
        "report = pd.DataFrame(\n",
        "    {\n",
        "        'Precision': [precision_LR[ix_LR], precision_RF[ix_RF], precision_XGB[ix_XGB]],\n",
        "        'Recall': [recall_LR[ix_LR], recall_RF[ix_RF], recall_XGB[ix_XGB]],\n",
        "        'F1-score': [fscore_LR[ix_LR], fscore_RF[ix_RF], fscore_XGB[ix_XGB]],\n",
        "        'ROC AUC score': [roc_auc_score_LR, roc_auc_score_RF, roc_auc_score_XGB]\n",
        "    },\n",
        "    index=['LogisticRegression', 'RandomForest', 'XGBoost']\n",
        ")\n",
        "\n",
        "report"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>ROC AUC score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.647431</td>\n",
              "      <td>0.837558</td>\n",
              "      <td>0.730323</td>\n",
              "      <td>0.784035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.696545</td>\n",
              "      <td>0.789631</td>\n",
              "      <td>0.740173</td>\n",
              "      <td>0.801536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.681708</td>\n",
              "      <td>0.809332</td>\n",
              "      <td>0.740058</td>\n",
              "      <td>0.803003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Precision    Recall  F1-score  ROC AUC score\n",
              "LogisticRegression   0.647431  0.837558  0.730323       0.784035\n",
              "RandomForest         0.696545  0.789631  0.740173       0.801536\n",
              "XGBoost              0.681708  0.809332  0.740058       0.803003"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHlLbm3qZeo6"
      },
      "source": [
        "# Выводы\n",
        "\n",
        "На самом деле все алгоритмы отработали достаточно хорошо. На основе F1 метрики линейнай регрессия уступает всего 1%, а roc_auc 1,5-2% При этом скорость логистической регрессии в разы выше, чем у более сложных алгоритмов Random Forest и тем более XGBoost.\n",
        "\n",
        "Однако в точности выигрывает Random Forest с отрывом в 5% от регрессии и 1,5% от XGB. При этом полнота у него меньше всех, а в случае с логистической регрессией почти 5%.\n",
        "\n",
        "Здесь надо уточнять, какие метрики наиболее важны. Но если базироваться на выявлении заболевания, то в этом случае нам важен высокий показатель recall, для большего охвата пациентов. Лучше провести для здоровых повторный анализ, чем пропустить заболевание. В таком раскладе обычная логистическая регрессия будет полезнее, как по скорости, так и по полноте."
      ]
    }
  ]
}